{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tweepy"
      ],
      "metadata": {
        "id": "es6oTzMDmUD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Libraries"
      ],
      "metadata": {
        "id": "ia_OxO7DmbhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import time\n",
        "import string\n",
        "import warnings\n",
        "\n",
        "# for all NLP related operations on text\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import *\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# To mock web-browser and scrap tweets\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "# To consume Twitter's API\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "\n",
        "# To identify the sentiment of text\n",
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "from textblob.np_extractors import ConllExtractor\n",
        "\n",
        "# ignoring all the warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# downloading stopwords corpus\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('conll2000')\n",
        "nltk.download('brown')\n",
        "stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "# for showing all the plots inline\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "y4jp-plFkILG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keys and tokens from the Twitter Dev Console\n",
        "consumer_key = 'xxxxxxxxxx3MvclRIx2RVlxxxxxxxxxxxxxx'\n",
        "consumer_secret = 'xxxxxxxNWtBm7fWpMBoK6Ewxxxxxxxxxxxx'\n",
        "access_token = 'xxxxxxxxxxxxxx6018-so5CPJrEbJKb3cxxxxxxxxxxx'\n",
        "access_token_secret = 'xxxxxxxxxxxxFTU7kxAjxxxxxxxx'"
      ],
      "metadata": {
        "id": "CYeYR-D6kIOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Fetch Tweets"
      ],
      "metadata": {
        "id": "vjs1AioCmfPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwitterClient(object):\n",
        "    def __init__(self):\n",
        "        #Initialization method.\n",
        "        try:\n",
        "            # create OAuthHandler object\n",
        "            auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "            # set access token and secret\n",
        "            auth.set_access_token(access_token, access_token_secret)\n",
        "            # create tweepy API object to fetch tweets\n",
        "            # add hyper parameter 'proxy' if executing from behind proxy\n",
        "            self.api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
        "\n",
        "        except tweepy.TweepError as e:\n",
        "            print(f\"Error: Tweeter Authentication Failed - \\n{str(e)}\")\n",
        "\n",
        "    def get_tweets(self, query, maxTweets = 1000):\n",
        "        #Function to fetch tweets.\n",
        "        # empty list to store parsed tweets\n",
        "        tweets = []\n",
        "        sinceId = None\n",
        "        max_id = -1\n",
        "        tweetCount = 0\n",
        "        tweetsPerQry = 100\n",
        "\n",
        "        while tweetCount < maxTweets:\n",
        "            try:\n",
        "                if (max_id <= 0):\n",
        "                    if (not sinceId):\n",
        "                        new_tweets = self.api.search(q=query, count=tweetsPerQry)\n",
        "                    else:\n",
        "                        new_tweets = self.api.search(q=query, count=tweetsPerQry,\n",
        "                                                since_id=sinceId)\n",
        "                else:\n",
        "                    if (not sinceId):\n",
        "                        new_tweets = self.api.search(q=query, count=tweetsPerQry,\n",
        "                                                max_id=str(max_id - 1))\n",
        "                    else:\n",
        "                        new_tweets = self.api.search(q=query, count=tweetsPerQry,\n",
        "                                                max_id=str(max_id - 1),\n",
        "                                                since_id=sinceId)\n",
        "                if not new_tweets:\n",
        "                    print(\"No more tweets found\")\n",
        "                    break\n",
        "\n",
        "                for tweet in new_tweets:\n",
        "                    parsed_tweet = {}\n",
        "                    parsed_tweet['tweets'] = tweet.text\n",
        "\n",
        "                    # appending parsed tweet to tweets list\n",
        "                    if tweet.retweet_count > 0:\n",
        "                        # if tweet has retweets, ensure that it is appended only once\n",
        "                        if parsed_tweet not in tweets:\n",
        "                            tweets.append(parsed_tweet)\n",
        "                    else:\n",
        "                        tweets.append(parsed_tweet)\n",
        "\n",
        "                tweetCount += len(new_tweets)\n",
        "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
        "                max_id = new_tweets[-1].id\n",
        "\n",
        "            except tweepy.TweepError as e:\n",
        "                # Just exit if any error\n",
        "                print(\"Tweepy error : \" + str(e))\n",
        "                break\n",
        "\n",
        "        return pd.DataFrame(tweets)"
      ],
      "metadata": {
        "id": "r_kAmyK4kISE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_client = TwitterClient()\n",
        "\n",
        "# calling function to get tweets\n",
        "tweets_df = twitter_client.get_tweets('AI', maxTweets=7000)\n",
        "print(f'tweets_df Shape - {tweets_df.shape}')\n",
        "tweets_df.head(10)"
      ],
      "metadata": {
        "id": "SlJK8Sw1lUTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch sentiments"
      ],
      "metadata": {
        "id": "okqciO3HnFu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_sentiment_using_textblob(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return 'pos' if analysis.sentiment.polarity >= 0 else 'neg'"
      ],
      "metadata": {
        "id": "VbEZExswll4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments_using_textblob = tweets_df.tweets.apply(lambda tweet: fetch_sentiment_using_textblob(tweet))\n",
        "pd.DataFrame(sentiments_using_textblob.value_counts())"
      ],
      "metadata": {
        "id": "ft8Qjljmll7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}